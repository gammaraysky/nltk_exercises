{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Amazon Book Reviews\n",
    "- A short exercise of positive/negative sentiment prediction.\n",
    "- comparison of approaches using:\n",
    "  - CountVectorizer\n",
    "  - Term Frequency-Inverse Document Frequency\n",
    "  - n-grams of words\n",
    "- text preprocessing:\n",
    "  - since book reviews, we only take words, ignore symbols and digits, make lowercase\n",
    "  - lemmatize using WordNet\n",
    "  - drop stop words like: 'the', 'is', etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5957</th>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3744</th>\n",
       "      <td>Aislinn is a little girl with big dreams. Afte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13641</th>\n",
       "      <td>This has the makings of a good story... unfort...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4448</th>\n",
       "      <td>I got this because I like collaborated short s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "id                                                             \n",
       "5957   Great short read.  I didn't want to put it dow...      1\n",
       "1776   I did not expect this type of book to be in li...      1\n",
       "3744   Aislinn is a little girl with big dreams. Afte...      1\n",
       "13641  This has the makings of a good story... unfort...      0\n",
       "4448   I got this because I like collaborated short s...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import nltk\n",
    "import os\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "float_formatter = \"{:.2f}\".format\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "\n",
    "##? LOAD DATA, PREP RELEVANT COLS\n",
    "reviews = pd.read_csv('./data/all_kindle_review.csv', index_col=[1])\n",
    "reviews.drop(['Unnamed: 0.1','asin','unixReviewTime','reviewerName','reviewerID','summary','reviewTime','helpful'], axis=1, inplace=True)\n",
    "reviews.index.name = 'id'\n",
    "\n",
    "##? SET BOOK RATINGS 4 AND 5 TO BE POSITIVE SENTIMENT LABEL, 1 AND 2 NEGATIVE, DROP 3\n",
    "reviews['label'] = reviews['rating'].apply(lambda x: 1 if x>3 else 0 if x<3 else -1)\n",
    "reviews = reviews.drop(reviews[reviews['label']==-1].index, axis=0)\n",
    "reviews.drop('rating', axis=1, inplace=True)\n",
    "reviews.columns = ['text','label']\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    6000\n",
      "0    4000\n",
      "Name: label, dtype: int64\n",
      "Mean length of positive reviews :  598.007\n",
      "Mean length of negative reviews :  579.159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##? LABEL CLASS PROPORTIONS\n",
    "print(reviews['label'].value_counts())\n",
    "# 1    6000\n",
    "# 0    4000\n",
    "\n",
    "##? MEAN LENGTH OF SPAM VS NON-SPAM TEXTS\n",
    "positive = reviews[reviews['label']==1]\n",
    "negative = reviews[reviews['label']==0]\n",
    "positivemeanlen = positive.text.str.len().mean()\n",
    "negativemeanlen = negative.text.str.len().mean()\n",
    "\n",
    "print('\\\n",
    "Mean length of positive reviews : {:>8.3f}\\n\\\n",
    "Mean length of negative reviews : {:>8.3f}\\n\\\n",
    "'.format(positivemeanlen, negativemeanlen))\n",
    "# Mean length of positive reviews :  598.007\n",
    "# Mean length of negative reviews :  579.159\n",
    "\n",
    "# No significant difference, so won't add as engineered feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer bag-of-words\n",
    "- ignore words that appear in less than 3 samples, ignore words that appear in more than half the samples.\n",
    "- only accept alphabets, ignore digits, symbols.\n",
    "- tokenize, lowercase, lemmatize, drop stop words.\n",
    "- create a sparse vector array of words and their counts.\n",
    "- run logistic regression and determine coefficients of features(i.e. words) that highly correlate with positive or negative labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##? DEFINE TEXT PREPROCESSING\n",
    "from nltk.corpus import stopwords\n",
    "sw_eng = set(stopwords.words('english'))\n",
    "\n",
    "class LemmaTokenizer():\n",
    "    def __init__(self):\n",
    "        self.wnl = nltk.WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        # lowercase, tokenize\n",
    "        words = nltk.word_tokenize(doc.lower())\n",
    "        # drop stopwords english\n",
    "        words = [ w for w in words if w not in sw_eng ]\n",
    "        # drop symbols and numbers, only keep words\n",
    "        words = [ self.wnl.lemmatize(t) for t in words if re.search(r'\\b[A-Za-z\\']+\\b', t) ]\n",
    "        words = [ w for w in words if w not in sw_eng ]\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Count:  9205\n",
      "Model Test Score using CountVectorizer: 0.8685\n",
      "\n",
      "HIGH OCCURRENCE WORDS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>'s</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7806</th>\n",
       "      <td>story</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>dean</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5861</th>\n",
       "      <td>parker</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3676</th>\n",
       "      <td>h</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7065</th>\n",
       "      <td>saul</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5403</th>\n",
       "      <td>n't</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>alex</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7472</th>\n",
       "      <td>slave</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4428</th>\n",
       "      <td>jane</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_name  count\n",
       "11             's     26\n",
       "7806        story     23\n",
       "2045         dean     22\n",
       "5861       parker     22\n",
       "3676            h     21\n",
       "7065         saul     17\n",
       "5403          n't     17\n",
       "263          alex     17\n",
       "7472        slave     17\n",
       "4428         jane     16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOW OCCURRENCE WORDS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5609</th>\n",
       "      <td>objection</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5599</th>\n",
       "      <td>nutshell</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>denial</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5607</th>\n",
       "      <td>obey</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5605</th>\n",
       "      <td>o.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5604</th>\n",
       "      <td>o'kane</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>denies</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5602</th>\n",
       "      <td>nyc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5600</th>\n",
       "      <td>nutty</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9204</th>\n",
       "      <td>~reviewed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_name  count\n",
       "5609    objection      1\n",
       "5599     nutshell      1\n",
       "2156       denial      1\n",
       "5607         obey      1\n",
       "5605           o.      1\n",
       "5604       o'kane      1\n",
       "2158       denies      1\n",
       "5602          nyc      1\n",
       "5600        nutty      1\n",
       "9204    ~reviewed      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORDS ASSOCIATED WITH POSITIVE SENTIMENT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>enjoyed</td>\n",
       "      <td>2.294729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4913</th>\n",
       "      <td>loved</td>\n",
       "      <td>2.060660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>enjoyable</td>\n",
       "      <td>1.727260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4794</th>\n",
       "      <td>liked</td>\n",
       "      <td>1.537970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3388</th>\n",
       "      <td>fun</td>\n",
       "      <td>1.336085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575</th>\n",
       "      <td>solve</td>\n",
       "      <td>1.272378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>great</td>\n",
       "      <td>1.260932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8969</th>\n",
       "      <td>well-written</td>\n",
       "      <td>1.253244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>pleasantly</td>\n",
       "      <td>1.248235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8080</th>\n",
       "      <td>tame</td>\n",
       "      <td>1.207037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_name      coef\n",
       "2746       enjoyed  2.294729\n",
       "4913         loved  2.060660\n",
       "2744     enjoyable  1.727260\n",
       "4794         liked  1.537970\n",
       "3388           fun  1.336085\n",
       "7575         solve  1.272378\n",
       "3599         great  1.260932\n",
       "8969  well-written  1.253244\n",
       "6067    pleasantly  1.248235\n",
       "8080          tame  1.207037"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORDS ASSOCIATED WITH NEGATIVE SENTIMENT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6171</th>\n",
       "      <td>potential</td>\n",
       "      <td>-1.465237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8626</th>\n",
       "      <td>unfortunately</td>\n",
       "      <td>-1.478243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4040</th>\n",
       "      <td>idea</td>\n",
       "      <td>-1.502744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663</th>\n",
       "      <td>okay</td>\n",
       "      <td>-1.547944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7800</th>\n",
       "      <td>stopped</td>\n",
       "      <td>-1.605004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954</th>\n",
       "      <td>horrible</td>\n",
       "      <td>-1.611842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>worst</td>\n",
       "      <td>-1.661471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8914</th>\n",
       "      <td>waste</td>\n",
       "      <td>-1.745521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>boring</td>\n",
       "      <td>-1.750775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7605</th>\n",
       "      <td>sorry</td>\n",
       "      <td>-1.771919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature_name      coef\n",
       "6171      potential -1.465237\n",
       "8626  unfortunately -1.478243\n",
       "4040           idea -1.502744\n",
       "5663           okay -1.547944\n",
       "7800        stopped -1.605004\n",
       "3954       horrible -1.611842\n",
       "9116          worst -1.661471\n",
       "8914          waste -1.745521\n",
       "969          boring -1.750775\n",
       "7605          sorry -1.771919"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews['text'], \n",
    "                                                    reviews['label'], \n",
    "                                                    random_state=0)\n",
    "\n",
    "##? Transform to Vect using CountVectorizer (simple bag-of-words)\n",
    "# vect = TfidfVectorizer().fit(X_train)\n",
    "# vect = CountVectorizer(min_df=3).fit(X_train)\n",
    "vect_countvec = CountVectorizer(\n",
    "    tokenizer=LemmaTokenizer(),\n",
    "    strip_accents = 'unicode',\n",
    "    lowercase = True,\n",
    "    max_df = 0.5,\n",
    "    min_df = 3\n",
    ").fit(X_train)\n",
    "X_train_vect = vect_countvec.transform(X_train)\n",
    "X_test_vect  = vect_countvec.transform(X_test)\n",
    "\n",
    "feature_names = np.array(vect_countvec.get_feature_names_out())\n",
    "# [w for w in feature_names if re.search('[0-9]+', w)] # sanity check that CountVectorizer indeed ignored numbers etc\n",
    "print('Feature Count: ', len(feature_names))\n",
    "\n",
    "##? MultinomialNaiveBayes using CountVectorizer\n",
    "# model_baseline_countvec = MultinomialNB(alpha=0.1).fit(X_train_vect, y_train)\n",
    "model_baseline_countvec = LogisticRegression(max_iter=1000).fit(X_train_vect, y_train)\n",
    "y_pred = model_baseline_countvec.predict(X_test_vect)\n",
    "score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print('Model Test Score using CountVectorizer: {:.4f}\\n'.format(score))\n",
    "\n",
    "##? Smallest and Largest tfidfs (word importance)\n",
    "# print as list\n",
    "# feature_names = np.array(vect.get_feature_names_out())\n",
    "# sorted_tfidf_index = X_train_vect.max(0).toarray()[0].argsort()\n",
    "# sorted_tfidf_values = X_train_vect.max(0).toarray()[0].sort()\n",
    "# print('Smallest tfidf:\\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\n",
    "# print('Largest tfidf: \\n{}'.format(feature_names[sorted_tfidf_index[:-11:-1]]))\n",
    "# print()\n",
    "#\n",
    "# display as dataframe\n",
    "train_vect_count = pd.DataFrame({'feature_name':feature_names, 'count':X_train_vect.max(0).toarray()[0]}).sort_values('count', ascending=False)\n",
    "print('HIGH OCCURRENCE WORDS')\n",
    "display(train_vect_count.head(10))\n",
    "print('LOW OCCURRENCE WORDS')\n",
    "display(train_vect_count.tail(10))\n",
    "\n",
    "##? Smallest and Largest Coefs\n",
    "# print as list\n",
    "# sorted_coef_index = model_baseline_countvec.coef_[0].argsort()\n",
    "# print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "# print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))\n",
    "# print()\n",
    "#\n",
    "# display as dataframe\n",
    "train_coefs = pd.DataFrame({'feature_name':feature_names, 'coef':model_baseline_countvec.coef_[0]}).sort_values('coef', ascending=False)\n",
    "print('WORDS ASSOCIATED WITH POSITIVE SENTIMENT')\n",
    "display(train_coefs.head(10))\n",
    "print('WORDS ASSOCIATED WITH NEGATIVE SENTIMENT')\n",
    "display(train_coefs.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS\n",
      "   -VE  +VE\n",
      "[[0.26 0.74]\n",
      " [0.91 0.09]\n",
      " [0.55 0.45]\n",
      " [0.55 0.45]\n",
      " [0.55 0.45]]\n"
     ]
    }
   ],
   "source": [
    "print('PREDICTIONS\\n   -VE  +VE')\n",
    "print(model_baseline_countvec.predict_proba(vect_countvec.transform([\n",
    "    'the book is great',\n",
    "    'it was really boring',\n",
    "    'but',\n",
    "    'don\\'t normally enjoy',\n",
    "    'don\\'t enjoy',\n",
    "])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf\n",
    "- ignore words that appear in less than 3 samples, ignore words that appear in more than half the samples.\n",
    "- only accept alphabets, ignore digits, symbols.\n",
    "- tokenize, lowercase, lemmatize, drop stop words.\n",
    "- create a sparse vector array of words and tf-idf values.\n",
    "- (tf-idf is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.)(value will be larger for words that are deemed important, i.e they appear often enough, yet still have differentiating factor i.e not words like 'the' which will appear everywhere and have low informative value)\n",
    "- run logistic regression and determine coefficients of features(i.e. words) that highly correlate with positive or negative labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Count:  9205\n",
      "Model_baseline_tfidf Test Score using TfidfVectorizer: 0.8609\n",
      "\n",
      "HIGH IMPORTANCE WORDS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>enjoyed</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>enjoyable</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>great</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4909</th>\n",
       "      <td>love</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9095</th>\n",
       "      <td>word</td>\n",
       "      <td>0.988182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>boring</td>\n",
       "      <td>0.921537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9187</th>\n",
       "      <td>yuck</td>\n",
       "      <td>0.885457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5384</th>\n",
       "      <td>must</td>\n",
       "      <td>0.879703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>cake</td>\n",
       "      <td>0.864934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2428</th>\n",
       "      <td>done</td>\n",
       "      <td>0.849839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_name     tfidf\n",
       "2746      enjoyed  1.000000\n",
       "2744    enjoyable  1.000000\n",
       "3599        great  1.000000\n",
       "4909         love  1.000000\n",
       "9095         word  0.988182\n",
       "969        boring  0.921537\n",
       "9187         yuck  0.885457\n",
       "5384         must  0.879703\n",
       "1146         cake  0.864934\n",
       "2428         done  0.849839"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOW IMPORTANCE WORDS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4918</th>\n",
       "      <td>lover-</td>\n",
       "      <td>0.075402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4560</th>\n",
       "      <td>kenyon'sfantasy</td>\n",
       "      <td>0.075402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>gennaro</td>\n",
       "      <td>0.074139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5770</th>\n",
       "      <td>overabundance</td>\n",
       "      <td>0.073362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>dionne</td>\n",
       "      <td>0.071214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7425</th>\n",
       "      <td>sister-in-law</td>\n",
       "      <td>0.070669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>assign</td>\n",
       "      <td>0.070086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>organic</td>\n",
       "      <td>0.064474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>attuned</td>\n",
       "      <td>0.061835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9204</th>\n",
       "      <td>~reviewed</td>\n",
       "      <td>0.060706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_name     tfidf\n",
       "4918           lover-  0.075402\n",
       "4560  kenyon'sfantasy  0.075402\n",
       "3473          gennaro  0.074139\n",
       "5770    overabundance  0.073362\n",
       "2300           dionne  0.071214\n",
       "7425    sister-in-law  0.070669\n",
       "537            assign  0.070086\n",
       "5725          organic  0.064474\n",
       "589           attuned  0.061835\n",
       "9204        ~reviewed  0.060706"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORDS ASSOCIATED WITH POSITIVE SENTIMENT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>enjoyed</td>\n",
       "      <td>6.203247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4913</th>\n",
       "      <td>loved</td>\n",
       "      <td>5.396721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>great</td>\n",
       "      <td>4.717249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4794</th>\n",
       "      <td>liked</td>\n",
       "      <td>3.531988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3388</th>\n",
       "      <td>fun</td>\n",
       "      <td>3.335159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4909</th>\n",
       "      <td>love</td>\n",
       "      <td>3.259024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8960</th>\n",
       "      <td>well</td>\n",
       "      <td>3.194049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>good</td>\n",
       "      <td>3.013144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>enjoyable</td>\n",
       "      <td>2.773525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3968</th>\n",
       "      <td>hot</td>\n",
       "      <td>2.736328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_name      coef\n",
       "2746      enjoyed  6.203247\n",
       "4913        loved  5.396721\n",
       "3599        great  4.717249\n",
       "4794        liked  3.531988\n",
       "3388          fun  3.335159\n",
       "4909         love  3.259024\n",
       "8960         well  3.194049\n",
       "3535         good  3.013144\n",
       "2744    enjoyable  2.773525\n",
       "3968          hot  2.736328"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORDS ASSOCIATED WITH NEGATIVE SENTIMENT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7266</th>\n",
       "      <td>sex</td>\n",
       "      <td>-2.862084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>bad</td>\n",
       "      <td>-2.883640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>finish</td>\n",
       "      <td>-2.907934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4040</th>\n",
       "      <td>idea</td>\n",
       "      <td>-2.992962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7605</th>\n",
       "      <td>sorry</td>\n",
       "      <td>-3.178622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>free</td>\n",
       "      <td>-3.224293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>nothing</td>\n",
       "      <td>-3.248386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>boring</td>\n",
       "      <td>-3.501281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8914</th>\n",
       "      <td>waste</td>\n",
       "      <td>-3.655241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5403</th>\n",
       "      <td>n't</td>\n",
       "      <td>-4.363071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_name      coef\n",
       "7266          sex -2.862084\n",
       "657           bad -2.883640\n",
       "3155       finish -2.907934\n",
       "4040         idea -2.992962\n",
       "7605        sorry -3.178622\n",
       "3341         free -3.224293\n",
       "5571      nothing -3.248386\n",
       "969        boring -3.501281\n",
       "8914        waste -3.655241\n",
       "5403          n't -4.363071"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "##? Transform to Vect using tfidf\n",
    "\n",
    "vect_tfidf = TfidfVectorizer(\n",
    "    tokenizer=LemmaTokenizer(),\n",
    "    strip_accents = 'unicode',\n",
    "    lowercase = True,\n",
    "    max_df = 0.5,\n",
    "    min_df = 3\n",
    ").fit(X_train)\n",
    "X_train_vect = vect_tfidf.transform(X_train)\n",
    "X_test_vect  = vect_tfidf.transform(X_test)\n",
    "\n",
    "feature_names = np.array(vect_tfidf.get_feature_names_out())\n",
    "print('Feature Count: ', len(feature_names))\n",
    "\n",
    "##? MultinomialNaiveBayes using tf-idf Vectorizer\n",
    "# model_baseline_tfidf = MultinomialNB(alpha=0.1).fit(X_train_vect, y_train)\n",
    "model_baseline_tfidf = LogisticRegression(max_iter=1000).fit(X_train_vect, y_train)\n",
    "y_pred = model_baseline_tfidf.predict(X_test_vect)\n",
    "score = roc_auc_score(y_test, y_pred)\n",
    "print('Model_baseline_tfidf Test Score using TfidfVectorizer: {:.4f}\\n'.format(score))\n",
    "\n",
    "##? Smallest and Largest tf-idfs\n",
    "# display as dataframe\n",
    "train_vect_tfidf = pd.DataFrame({'feature_name':feature_names, 'tfidf':X_train_vect.max(0).toarray()[0]}).sort_values('tfidf', ascending=False)\n",
    "print('HIGH IMPORTANCE WORDS')\n",
    "display(train_vect_tfidf.head(10))\n",
    "print('LOW IMPORTANCE WORDS')\n",
    "display(train_vect_tfidf.tail(10))\n",
    "\n",
    "\n",
    "##? Smallest and Largest Coefs\n",
    "# display as dataframe\n",
    "train_coefs = pd.DataFrame({'feature_name':feature_names, 'coef':model_baseline_tfidf.coef_[0]}).sort_values('coef', ascending=False)\n",
    "print('WORDS ASSOCIATED WITH POSITIVE SENTIMENT')\n",
    "display(train_coefs.head(10))\n",
    "print('WORDS ASSOCIATED WITH NEGATIVE SENTIMENT')\n",
    "display(train_coefs.tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS\n",
      "   -VE  +VE\n",
      "[[0.01 0.99]\n",
      " [0.97 0.03]\n",
      " [0.43 0.57]\n",
      " [0.49 0.51]\n",
      " [0.61 0.39]]\n"
     ]
    }
   ],
   "source": [
    "print('PREDICTIONS\\n   -VE  +VE')\n",
    "print(model_baseline_tfidf.predict_proba(vect_tfidf.transform([\n",
    "    'the book is great',\n",
    "    'it was really boring',\n",
    "    'but',\n",
    "    'don\\'t normally enjoy',\n",
    "    'don\\'t enjoy',\n",
    "])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem is, both of the above bag-of-word approaches do not take into account structure, like any word associations and orders. the last two reviews mean different things but have similar words, and don't have strong prediction probabilities.\n",
    "\n",
    "We will use n-grams of words to improve the model.\n",
    "\n",
    "### tf-idf & n-grams\n",
    "- ignore words that appear in less than 5 samples, ignore words that appear in more than half the samples.\n",
    "- only accept alphabets, ignore digits, symbols.\n",
    "- tokenize, lowercase, lemmatize, drop stop words.\n",
    "- create n-grams of words. e.g. in 'this is a sentence'\n",
    "  - bigrams would be 'this is', 'is a', 'a sentence'\n",
    "  - trigrams would be 'this is a', 'is a sentence'\n",
    "  - and so on, n-grams being n order of word lengths.\n",
    "  - by doing so we will capture a sense of word orders and distinguish between 'not bad, quite good' vs 'quite bad, not good'\n",
    "  - of course, the amount of ngrams we use will make number of features explode significantly and increase computation. thus we increased min_df to 5 above.\n",
    "- create a sparse vector array of words(and ngrams) and tf-idf values.\n",
    "- run logistic regression and determine coefficients of features(i.e. words) that highly correlate with positive or negative labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Count:  13661\n",
      "Model_ngram_tfidf Test Score using TfidfVectorizer and trigrams of words: 0.8699\n",
      "\n",
      "HIGH IMPORTANCE WORDS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6941</th>\n",
       "      <td>love</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3672</th>\n",
       "      <td>enjoyable</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13318</th>\n",
       "      <td>word word</td>\n",
       "      <td>0.884972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>great book</td>\n",
       "      <td>0.876010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>cake</td>\n",
       "      <td>0.847588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>boring</td>\n",
       "      <td>0.846285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6649</th>\n",
       "      <td>like like</td>\n",
       "      <td>0.838166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10861</th>\n",
       "      <td>sith</td>\n",
       "      <td>0.835648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>enjoyed book</td>\n",
       "      <td>0.834944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8666</th>\n",
       "      <td>passionate</td>\n",
       "      <td>0.828153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature_name     tfidf\n",
       "6941           love  1.000000\n",
       "3672      enjoyable  1.000000\n",
       "13318     word word  0.884972\n",
       "5157     great book  0.876010\n",
       "1999           cake  0.847588\n",
       "1825         boring  0.846285\n",
       "6649      like like  0.838166\n",
       "10861          sith  0.835648\n",
       "3680   enjoyed book  0.834944\n",
       "8666     passionate  0.828153"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOW IMPORTANCE WORDS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13135</th>\n",
       "      <td>werewolf romanceher</td>\n",
       "      <td>0.063334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13259</th>\n",
       "      <td>wolf chronicle</td>\n",
       "      <td>0.063334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2813</th>\n",
       "      <td>courtesy romance</td>\n",
       "      <td>0.062973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>dionne courtesy</td>\n",
       "      <td>0.062973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>dionne</td>\n",
       "      <td>0.062973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>arend'stidal wave</td>\n",
       "      <td>0.062133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12864</th>\n",
       "      <td>vivian arend'stidal</td>\n",
       "      <td>0.062133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7952</th>\n",
       "      <td>nature book</td>\n",
       "      <td>0.062133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>arend'stidal</td>\n",
       "      <td>0.062133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9170</th>\n",
       "      <td>protective instinct</td>\n",
       "      <td>0.061302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature_name     tfidf\n",
       "13135  werewolf romanceher  0.063334\n",
       "13259       wolf chronicle  0.063334\n",
       "2813      courtesy romance  0.062973\n",
       "3249       dionne courtesy  0.062973\n",
       "3248                dionne  0.062973\n",
       "903      arend'stidal wave  0.062133\n",
       "12864  vivian arend'stidal  0.062133\n",
       "7952           nature book  0.062133\n",
       "902           arend'stidal  0.062133\n",
       "9170   protective instinct  0.061302"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORDS ASSOCIATED WITH POSITIVE SENTIMENT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3677</th>\n",
       "      <td>enjoyed</td>\n",
       "      <td>5.464269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7013</th>\n",
       "      <td>loved</td>\n",
       "      <td>5.281393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154</th>\n",
       "      <td>great</td>\n",
       "      <td>4.613258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6941</th>\n",
       "      <td>love</td>\n",
       "      <td>3.566246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>liked</td>\n",
       "      <td>3.317127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4653</th>\n",
       "      <td>fun</td>\n",
       "      <td>3.291387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13073</th>\n",
       "      <td>well</td>\n",
       "      <td>2.981591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10493</th>\n",
       "      <td>series</td>\n",
       "      <td>2.909122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>good</td>\n",
       "      <td>2.776183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5608</th>\n",
       "      <td>hot</td>\n",
       "      <td>2.775221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9374</th>\n",
       "      <td>read</td>\n",
       "      <td>2.547393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13292</th>\n",
       "      <td>wonderful</td>\n",
       "      <td>2.542477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3672</th>\n",
       "      <td>enjoyable</td>\n",
       "      <td>2.518541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3481</th>\n",
       "      <td>easy</td>\n",
       "      <td>2.371795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6558</th>\n",
       "      <td>life</td>\n",
       "      <td>2.349972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8096</th>\n",
       "      <td>nice</td>\n",
       "      <td>2.333057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>always</td>\n",
       "      <td>2.238522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>enjoyed book</td>\n",
       "      <td>2.237653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>'s</td>\n",
       "      <td>2.057658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6156</th>\n",
       "      <td>keep</td>\n",
       "      <td>1.940568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5044</th>\n",
       "      <td>good read</td>\n",
       "      <td>1.929367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8732</th>\n",
       "      <td>perfect</td>\n",
       "      <td>1.906525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>excellent</td>\n",
       "      <td>1.887730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9251</th>\n",
       "      <td>put</td>\n",
       "      <td>1.831339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9675</th>\n",
       "      <td>really enjoyed</td>\n",
       "      <td>1.827611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11804</th>\n",
       "      <td>sweet</td>\n",
       "      <td>1.817395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10649</th>\n",
       "      <td>sexy</td>\n",
       "      <td>1.810656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10390</th>\n",
       "      <td>see</td>\n",
       "      <td>1.809191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7911</th>\n",
       "      <td>n't wait</td>\n",
       "      <td>1.780401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12884</th>\n",
       "      <td>wait</td>\n",
       "      <td>1.731997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_name      coef\n",
       "3677          enjoyed  5.464269\n",
       "7013            loved  5.281393\n",
       "5154            great  4.613258\n",
       "6941             love  3.566246\n",
       "6701            liked  3.317127\n",
       "4653              fun  3.291387\n",
       "13073            well  2.981591\n",
       "10493          series  2.909122\n",
       "4986             good  2.776183\n",
       "5608              hot  2.775221\n",
       "9374             read  2.547393\n",
       "13292       wonderful  2.542477\n",
       "3672        enjoyable  2.518541\n",
       "3481             easy  2.371795\n",
       "6558             life  2.349972\n",
       "8096             nice  2.333057\n",
       "717            always  2.238522\n",
       "3680     enjoyed book  2.237653\n",
       "91                 's  2.057658\n",
       "6156             keep  1.940568\n",
       "5044        good read  1.929367\n",
       "8732          perfect  1.906525\n",
       "3947        excellent  1.887730\n",
       "9251              put  1.831339\n",
       "9675   really enjoyed  1.827611\n",
       "11804           sweet  1.817395\n",
       "10649            sexy  1.810656\n",
       "10390             see  1.809191\n",
       "7911         n't wait  1.780401\n",
       "12884            wait  1.731997"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORDS ASSOCIATED WITH NEGATIVE SENTIMENT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8917</th>\n",
       "      <td>point</td>\n",
       "      <td>-1.817347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12991</th>\n",
       "      <td>waste time</td>\n",
       "      <td>-1.879519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5596</th>\n",
       "      <td>horrible</td>\n",
       "      <td>-1.882501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8938</th>\n",
       "      <td>poor</td>\n",
       "      <td>-1.893254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>n't even</td>\n",
       "      <td>-1.916898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>better</td>\n",
       "      <td>-1.930300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8942</th>\n",
       "      <td>poorly</td>\n",
       "      <td>-1.930550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12688</th>\n",
       "      <td>unfortunately</td>\n",
       "      <td>-1.948736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>-1.957050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5465</th>\n",
       "      <td>heroine</td>\n",
       "      <td>-2.026169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13391</th>\n",
       "      <td>would</td>\n",
       "      <td>-2.037572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7586</th>\n",
       "      <td>money</td>\n",
       "      <td>-2.156019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8984</th>\n",
       "      <td>potential</td>\n",
       "      <td>-2.161778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>chapter</td>\n",
       "      <td>-2.193011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10431</th>\n",
       "      <td>seemed</td>\n",
       "      <td>-2.206643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8866</th>\n",
       "      <td>plot</td>\n",
       "      <td>-2.224434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8271</th>\n",
       "      <td>okay</td>\n",
       "      <td>-2.228709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6368</th>\n",
       "      <td>lack</td>\n",
       "      <td>-2.263658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>could</td>\n",
       "      <td>-2.500193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>even</td>\n",
       "      <td>-2.535575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5710</th>\n",
       "      <td>idea</td>\n",
       "      <td>-2.683036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10607</th>\n",
       "      <td>sex</td>\n",
       "      <td>-2.884666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>bad</td>\n",
       "      <td>-2.911961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334</th>\n",
       "      <td>finish</td>\n",
       "      <td>-2.912776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11026</th>\n",
       "      <td>sorry</td>\n",
       "      <td>-2.973883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4581</th>\n",
       "      <td>free</td>\n",
       "      <td>-3.044876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8162</th>\n",
       "      <td>nothing</td>\n",
       "      <td>-3.084636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12989</th>\n",
       "      <td>waste</td>\n",
       "      <td>-3.086500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>boring</td>\n",
       "      <td>-3.485677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7737</th>\n",
       "      <td>n't</td>\n",
       "      <td>-4.537631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_name      coef\n",
       "8917           point -1.817347\n",
       "12991     waste time -1.879519\n",
       "5596        horrible -1.882501\n",
       "8938            poor -1.893254\n",
       "7784        n't even -1.916898\n",
       "1335          better -1.930300\n",
       "8942          poorly -1.930550\n",
       "12688  unfortunately -1.948736\n",
       "3266    disappointed -1.957050\n",
       "5465         heroine -2.026169\n",
       "13391          would -2.037572\n",
       "7586           money -2.156019\n",
       "8984       potential -2.161778\n",
       "2164         chapter -2.193011\n",
       "10431         seemed -2.206643\n",
       "8866            plot -2.224434\n",
       "8271            okay -2.228709\n",
       "6368            lack -2.263658\n",
       "2729           could -2.500193\n",
       "3831            even -2.535575\n",
       "5710            idea -2.683036\n",
       "10607            sex -2.884666\n",
       "1145             bad -2.911961\n",
       "4334          finish -2.912776\n",
       "11026          sorry -2.973883\n",
       "4581            free -3.044876\n",
       "8162         nothing -3.084636\n",
       "12989          waste -3.086500\n",
       "1825          boring -3.485677\n",
       "7737             n't -4.537631"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##? Transform to Vect using tfidf, include up to 3-word phrases as features\n",
    "vect_ngram_tfidf = TfidfVectorizer(\n",
    "    tokenizer=LemmaTokenizer(),\n",
    "    strip_accents = 'unicode',\n",
    "    lowercase = True,\n",
    "    max_df = 0.5,\n",
    "    min_df = 5,\n",
    "    ngram_range=(1,2),\n",
    ").fit(X_train)\n",
    "X_train_vect = vect_ngram_tfidf.transform(X_train)\n",
    "X_test_vect  = vect_ngram_tfidf.transform(X_test)\n",
    "\n",
    "feature_names = np.array(vect_ngram_tfidf.get_feature_names_out())\n",
    "print('Feature Count: ', len(feature_names))\n",
    "\n",
    "##? MultinomialNaiveBayes using tf-idf Vectorizer\n",
    "# model_ngram_tfidf = MultinomialNB(alpha=0.1).fit(X_train_vect, y_train)\n",
    "model_ngram_tfidf = LogisticRegression(max_iter=1000).fit(X_train_vect, y_train)\n",
    "y_pred = model_ngram_tfidf.predict(X_test_vect)\n",
    "score = roc_auc_score(y_test, y_pred)\n",
    "print('Model_ngram_tfidf Test Score using TfidfVectorizer and trigrams of words: {:.4f}\\n'.format(score))\n",
    "\n",
    "##? Smallest and Largest tf-idfs\n",
    "# display as dataframe\n",
    "train_vect_tfidf = pd.DataFrame({'feature_name':feature_names, 'tfidf':X_train_vect.max(0).toarray()[0]}).sort_values('tfidf', ascending=False)\n",
    "print('HIGH IMPORTANCE WORDS')\n",
    "display(train_vect_tfidf.head(10))\n",
    "print('LOW IMPORTANCE WORDS')\n",
    "display(train_vect_tfidf.tail(10))\n",
    "\n",
    "##? Smallest and Largest Coefs\n",
    "# display as dataframe\n",
    "train_coefs = pd.DataFrame({'feature_name':feature_names, 'coef':model_ngram_tfidf.coef_[0]}).sort_values('coef', ascending=False)\n",
    "print('WORDS ASSOCIATED WITH POSITIVE SENTIMENT')\n",
    "display(train_coefs.head(30))\n",
    "print('WORDS ASSOCIATED WITH NEGATIVE SENTIMENT')\n",
    "display(train_coefs.tail(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS\n",
      "   -VE  +VE\n",
      "[[0.07 0.93]\n",
      " [0.87 0.13]\n",
      " [0.44 0.56]\n",
      " [0.44 0.56]\n",
      " [0.70 0.30]]\n"
     ]
    }
   ],
   "source": [
    "print('PREDICTIONS\\n   -VE  +VE')\n",
    "print(model_ngram_tfidf.predict_proba(vect_ngram_tfidf.transform([\n",
    "    'the book is great',\n",
    "    'it was really boring',\n",
    "    'but',\n",
    "    'don\\'t normally enjoy',\n",
    "    'don\\'t enjoy',\n",
    "])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- with n-grams, the predictions probabilities are better for the last 2 test entries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('python')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "481cec52f7d095282728c60bb70d451310b560bc752e0d5557e6790a59f74331"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
